## Key idea 
- we can’t afford to run a physical GPU cluster
- emulate one as faithfully as possible in code and search for optimal policies through simulation.

The sandbox reproduces on‑the‑ground bottlenecks—file transfer, heterogeneous GPU throughput, spot availability, pricing, budgets, hard deadlines—so that scheduling strategies can be designed, A/B‑tested, and refined entirely offline.

## Progress

- Data Models – Implemented Task, Provider, and their containers (Tasks, Providers).
- Scheduler – Finished EDF + greedy algorithm that honours file‑transfer latency, compute time, budget and deadline constraints.
- Objective Function – 5‑term weighted sum (time, budget overrun, deadline overrun, provider profit, idle penalty).
- CLI Simulator – Full pipeline: config.json → schedule → KPI report (makespan, idle ratio, total cost).
- Utilities – Helper functions such as merge_intervals() plus unit‑test suite.
- Documentation – English README and developer guide draft published.

## Roadmap

### Library‑backed Optimizer
Implement a scheduler using established optimisation libraries (e.g. Google OR‑Tools or Timefold Solver).  Users specify constraints and objective weights in JSON/YAML, the solver returns an optimised schedule.

### In‑house Scheduler & BenchmarkDesign our own heuristic 
meta‑heuristic scheduler, run side‑by‑side benchmarks against the library‑backed version, and—if we demonstrate a clear advantage—package and release the code as an open‑source contribution.


